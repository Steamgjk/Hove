scp -r beatbat@12.12.10.13:/home/beatbat/pytorch-distributed-example/mnist-pytorch-v1.0.1/* /home/beatbat/pytorch-distributed-example/mnist-pytorch-v1.0.1/       

scp -r beatbat@12.12.10.13:/home/beatbat/Pytorch-Work /home/beatbat/
gcc -shared -o glue.so -fPIC glue.c -lpthread

ps -aux|grep python|cut -c 9-15|xargs kill -9

/usr/local/cuda/bin/nvprof --profile-from-start off --export-profile test.nvvp -f --print-gpu-trace --log-file test.txt  python worker_process-p2p.py --wid 0 --bs 32

/usr/local/cuda/bin/nvprof --profile-from-start off --metrics achieved_occupancy --export-profile "base"${WID}".nvvp" -f --print-gpu-trace --log-file test.txt  python worker-allreduce-baseline.py --wid $WID --wn 4 --bs 4 --nproc 1 --prt 23113


/usr/local/cuda/bin/nvprof --profile-from-start off --metrics achieved_occupancy --export-profile myprof.nvvp  -f --print-gpu-trace --log-file test.txt  



nvprof -o prof.nvvp python worker_process-all-reduce-static.py  --wid $WID --wn 4 --bs 4  --prt 23113

nvprof --profile-child-processes --profile-from-start off --metrics achieved_occupancy  --print-gpu-trace -o baseline-prof-%p.nvvp python worker-allreduce-baseline.py --wid $WID --wn 4 --bs 4 --nproc 1 --prt 23113


 nvprof --profile-child-processes --profile-from-start off --metrics achieved_occupancy  --print-gpu-trace --log-file gpu_trace-%p.txt -o baseline-prof-%p.nvvp python worker-allreduce-baseline.py --wid $WID --wn 4 --bs 4 --nproc 1 --prt 23113


nvprof --profile-child-processes --profile-from-start off --metrics achieved_occupancy  --print-gpu-trace --log-file flex-gpu_trace-%p.txt -o flex-prof-%p.nvvp python Flex_demo.py --wid $WID --wn 4 --bs 4 --subbs 4 --prt 23112 --ip 12.12.11.11


nvprof --profile-child-processes --profile-from-start off --print-gpu-trace --log-file flex-gpu_trace-%p.txt python Flex_demo.py --wid $WID --wn 4 --bs 4 --subbs 4 --prt 23112 --ip 12.12.11.11

3.55 ~ 3.56    10ms   

772ms ~ 782ms  10ms 

bs1  110~120ms  
bs4  ~0.4s 400ms

160459560

1605632 
1605632 1605632
401408  1605632
		1605632


bs1  5.63  6.45  700ms

IP:
39/40/97/44

https://docs.nvidia.com/cuda/profiler-users-guide/index.html

	
106.13.68.218
export GLOO_SOCKET_IFNAME=eth2

export GLOO_SOCKET_IFNAME=eth3

export CUDA_VISIBLE_DEVICES='0'
export GLOO_SOCKET_IFNAME=enp0s3
python worker-allreduce-baseline.py --wid $WID --wn 3 --bs 4 --nproc 1 --prt 23112 --ip 172.16.0.64
python MultiPipe_bk.py --wid $WID --wn 3 --bs 4 --subbs 4 --nproc 3 --prt 23112 --ip 172.16.0.64

useradd beatbat
vim /etc/sudoers
passwd beatbat
scp -r beatbat@12.12.10.13:/home/beatbat/Anaconda3-5.3.1-Linux-x86_64.sh /home/beatbat/
scp -r beatbat@12.12.10.13:/home/beatbat/.pip /home/beatbat/

source /home/beatbat/anaconda3/etc/profile.d/conda.sh
conda config --prepend channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/



conda config --remove-key channels
conda config --prepend channels https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
conda create -n py37 python=3.7
conda activate py37
conda install pytorch torchvision cudatoolkit=9.0 -c https://mirrors.ustc.edu.cn/anaconda/pkgs/free/
conda deactivate

[global]
index-url = https://pypi.mirrors.ustc.edu.cn/simple/
[install]
trusted-host=mirrows.aliyun.com

pip install --upgrade pip
pip install torch torchvision torchsummary

scp -r beatbat@12.12.10.13:/home/beatbat/.pip /home/beatbat/

scp -r beatbat@12.12.10.13:/home/beatbat/*.sh /home/beatbat/

scp -r beatbat@12.12.10.13:/home/beatbat/Pytorch-Work /home/beatbat/

scp -r beatbat@12.12.10.12:/home/beatbat/Pytorch-Work /home/beatbat/

scp -r beatbat@12.12.10.11:/home/beatbat/Pytorch-Work /home/beatbat/

source /home/beatbat/anaconda3/etc/profile.d/conda.sh

python MultiPipe.py --wid $WID --wn 4 --bs 8 --subbs 1


# 激活环境
source activate
# 退出环境
source deactivate


ssh admin@192.168.15.24  密码admin， enable，然后configure terminal进入配置界面

interface ethernet 1/5 speed 10G force  10.15
interface ethernet 1/25 speed 10G force  11.15

interface ethernet 1/21 speed 40G force
interface ethernet 1/22 speed 40G force
interface ethernet 1/23 speed 40G force
interface ethernet 1/24 speed 40G force


python MultiPipe.py --wid $WID --wn 9 --bs 4 --subbs 1 --nproc 1 --gn 3 --gsz 3 --prt 23112

python worker-allreduce-baseline.py --wid $WID --wn 9 --bs 4 --nproc 1 --prt 23112

python worker-allreduce-baseline.py --wid $WID --wn 4 --bs 4 --nproc 1 --prt 23112

python MultiPipe_bk.py --wid $WID --wn 3 --bs 4 --subbs 4 --nproc 3 --prt 23112 --ip 12.12.11.11

python Flex_demo.py --wid $WID --wn 4 --bs 32 --subbs 8 --prt 23112 --ip 12.12.11.11

watch -n 0.1 -d nvidia-smi

https://discuss.pytorch.org/t/how-to-call-cudaprofilerstart-cudaprofilerstop/33817

https://z0ngqing.github.io/publication/

export GLOO_SOCKET_IFNAME=eth3

Relu 层不能开头，因为反向传播时候没有backward_ctx
Conv, batchNorm, MaxPool，AvgPool 均可以打头



##Baidu 
python Flex_demo.py --wid $WID --wn 4 --bs 4 --subbs 4 --prt 23112 --ip 172.16.0.63
python worker-allreduce-baseline.py --wid $WID --wn 4 --bs 4 --nproc 1 --prt 23112  --ip 172.16.0.63


nvprof --profile-child-processes --profile-from-start off --metrics achieved_occupancy -o flex-prof-%p.nvvp python Flex_demo.py --wid $WID --wn 4 --bs 64 --subbs 32 --prt 23112 --ip 172.16.0.63


python Flex_demo.py --wid $WID --wn 4 --bs 64 --subbs 32 --prt 23112 --ip 172.16.0.63


nvprof --profile-child-processes --profile-from-start off --metrics achieved_occupancy -o base-prof-%p.nvvp python worker-allreduce-baseline.py --wid $WID --wn 4 --bs 32 --nproc 1 --prt 23112  --ip 172.16.0.63

train_proc pid= 12879
train_proc pid= 17384
train_proc pid= 30737
train_proc pid= 5672


64-32
train_proc pid= 15190
train_proc pid= 19569
train_proc pid= 2140
train_proc pid= 7832


Base：

train pid =  14487
train pid =  18922
train pid =  662
train pid =  7208


####### BEATBAT###############
export GLOO_SOCKET_IFNAME=eth3

/usr/local/cuda/bin/nvprof --profile-child-processes --profile-from-start off --metrics achieved_occupancy -o flex-prof-%p.nvvp python Flex_demo.py --wid $WID --wn 4 --bs 128 --subbs 32 --prt 23112 --ip 12.12.11.11

python Flex_demo.py --wid $WID --wn 4 --bs 4 --subbs 4 --prt 23112 --ip 12.12.11.11
python worker-allreduce-baseline.py --wid $WID --wn 4 --bs 64 --nproc 1 --prt 23112  --ip 12.12.11.11

train_proc pid= 27991
train_proc pid= 685
train_proc pid= 17638
train_proc pid= 3853


nvidia-smi pmon -i 1 -d 1 -f log

nvidia-smi pmon -i 1 -c 100 -f flex-prof-log


nvidia-smi pmon -i 0 -c 100 -f flex-prof-blog.csv

nvidia-smi pmon -i 0 -c 100 -f base32-prof-blog.csv

Nmap 7.01 ( https://nmap.org ) at 2019-12-22 15:01 CST

beatbat@g4-nasp:~$ arp -a|grep -i 'EC:0D:9A:6B:D5:34'


0        torch.Size([1, 64, 224, 224])   <class 'torch.nn.modules.conv.Conv2d'>
1        torch.Size([1, 64, 224, 224])   <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
2        torch.Size([1, 64, 224, 224])   <class 'torch.nn.modules.activation.ReLU'>
3        torch.Size([1, 64, 224, 224])   <class 'torch.nn.modules.conv.Conv2d'>
4        torch.Size([1, 64, 224, 224])   <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
5        torch.Size([1, 64, 224, 224])   <class 'torch.nn.modules.activation.ReLU'>
6        torch.Size([1, 64, 112, 112])   <class 'torch.nn.modules.pooling.MaxPool2d'>
7        torch.Size([1, 128, 112, 112])          <class 'torch.nn.modules.conv.Conv2d'>
8        torch.Size([1, 128, 112, 112])          <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
9        torch.Size([1, 128, 112, 112])          <class 'torch.nn.modules.activation.ReLU'>
10       torch.Size([1, 128, 112, 112])          <class 'torch.nn.modules.conv.Conv2d'>
11       torch.Size([1, 128, 112, 112])          <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
12       torch.Size([1, 128, 112, 112])          <class 'torch.nn.modules.activation.ReLU'>
13       torch.Size([1, 128, 56, 56])    <class 'torch.nn.modules.pooling.MaxPool2d'>
14       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.conv.Conv2d'>
15       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
16       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.activation.ReLU'>
17       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.conv.Conv2d'>
18       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
19       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.activation.ReLU'>
20       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.conv.Conv2d'>
21       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
22       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.activation.ReLU'>
23       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.conv.Conv2d'>
24       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
25       torch.Size([1, 256, 56, 56])    <class 'torch.nn.modules.activation.ReLU'>
26       torch.Size([1, 256, 28, 28])    <class 'torch.nn.modules.pooling.MaxPool2d'>
27       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.conv.Conv2d'>
28       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
29       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.activation.ReLU'>
30       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.conv.Conv2d'>
31       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
32       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.activation.ReLU'>
33       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.conv.Conv2d'>
34       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
35       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.activation.ReLU'>
36       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.conv.Conv2d'>
37       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
38       torch.Size([1, 512, 28, 28])    <class 'torch.nn.modules.activation.ReLU'>
39       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.pooling.MaxPool2d'>
40       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.conv.Conv2d'>
41       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
42       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.activation.ReLU'>
43       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.conv.Conv2d'>
44       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
45       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.activation.ReLU'>
46       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.conv.Conv2d'>
47       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
48       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.activation.ReLU'>
49       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.conv.Conv2d'>
50       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.batchnorm.BatchNorm2d'>
51       torch.Size([1, 512, 14, 14])    <class 'torch.nn.modules.activation.ReLU'>
52       torch.Size([1, 512, 7, 7])      <class 'torch.nn.modules.pooling.MaxPool2d'>
53       torch.Size([1, 512, 7, 7])      <class 'torch.nn.modules.pooling.AvgPool2d'>
54       torch.Size([1, 4096])   <class 'torch.nn.modules.linear.Linear'>
55       torch.Size([1, 4096])   <class 'torch.nn.modules.linear.Linear'>
56       torch.Size([1, 4096])   <class 'torch.nn.modules.linear.Linear'>



bs=4, channel=[128,128] layer=2    0.22075464487075805
bs=4, channel=[128,128] layer=3    0.32630832433700563



python Stanza.py --wid $WID --wn 8 --convn 7 --subbs 37 --subitern 4 --ip 12.12.10.101 --prt 23456

9.980431377887726       25.850586034949878
10.927093040943145      18.76070783252944
9.127675199508667       14.023286017768259


7.044942617416382       147.05584647897902
10.55193704366684       97.80194818537089
11.330711770057679      90.46210165795985
10.095028126239777      101.43607201433547
14.808944368362427      68.87729298106558


printf("%c")



python Dy-TokenS.py --wn 8 --subbs 4 --tokencap 1 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 4 --tokencap 1 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 4  --sleepn 0 --subbs 4 --tokencap 1 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 4 --tokencap 1 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1



python Dy-TokenS.py --wn 8 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1
3.0970443725585937

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 2  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1
3.454152743021647

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 4  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1
3.378960907459259

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1
3.347865343093872

###################################
python Dy-TokenS.py --wn 8 --subbs 4 --tokencap 1 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 4 --tokencap 1 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 4 --tokencap 1 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1


python Dy-TokenS.py --wn 8 --subbs 16 --tokencap 4 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 16 --tokencap 4 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 16 --tokencap 4 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1


python Dy-TokenS.py --wn 8 --subbs 32 --tokencap 8 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 32 --tokencap 4 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 2  --sleepn 0 --subbs 32 --tokencap 4 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1


python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 4  --sleepn 0 --subbs 32 --tokencap 4 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 32 --tokencap 4 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1



######################################
 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 2  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 4  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1


 python Dy-TokenS.py --wn 8 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1
5.828352848688762

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 4  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1
 6.075908184051514

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 2  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1
 6.154907703399658


 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1
 5.917973518371582



 python Dy-TokenS.py --wn 8 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

  python Dy-TokenS.py --wn 8 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1

 python Dy-TokenS.py --wn 8 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1


python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 64 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1


 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1


 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 4  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1


 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 2  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 4  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 8  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 4 4 4 1

 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 2 2 2 1


 python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 1 1 1 1

  python Dy-FelaWo.py --wid $WID --wn 8 --fcwn 1  --sleepn 0 --subbs 128 --tokencap 16 --ip 12.12.10.101 --prt 23479  --weight 1 8 8 8 1